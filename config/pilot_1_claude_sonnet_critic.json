{
  "pilotId": "pilot_1_claude_sonnet_critic",
  "pilotName": "Claude 3.5 Sonnet as Critic",
  "description": "Test Claude 3.5 Sonnet's reliability as a critic with GPT-4o designers. Web + Marketing lanes to expose implementation-hallucination and claim-hallucination.",
  "challengerModel": {
    "id": "claude-3-5-sonnet-20240620",
    "provider": "anthropic",
    "name": "Claude 3.5 Sonnet",
    "contextWindow": 200000,
    "pricing": {
      "input": 3.15,
      "output": 15.75,
      "unit": "per 1M tokens"
    }
  },
  "pilotConfig": {
    "lanes": ["web", "marketing"],
    "repsPerLane": 2,
    "totalRuns": 4,
    "concurrency": 2,
    "strictMode": {
      "enableLadder": false,
      "allowModelFallback": false,
      "requireSchemaHashMatch": true,
      "rejectTruncation": true,
      "rejectSilentModelFallback": true,
      "rejectMissingArtifacts": true
    }
  },
  "stack": {
    "designer_systems_fast": {
      "modelId": "gpt-4o-2024-08-06",
      "provider": "openai",
      "role": "systems",
      "maxTokens": 2000,
      "temperature": 0.7,
      "note": "Control baseline - reliable designer"
    },
    "designer_brand_fast": {
      "modelId": "gpt-4o-2024-08-06",
      "provider": "openai",
      "role": "brand",
      "maxTokens": 2000,
      "temperature": 0.7,
      "note": "Control baseline - reliable designer"
    },
    "design_critic_ruthless": {
      "modelId": "claude-3-5-sonnet-20240620",
      "provider": "anthropic",
      "role": "critic",
      "maxTokens": 4000,
      "temperature": 0.7,
      "note": "CHALLENGER - testing critic reliability"
    }
  },
  "acceptanceCriteria": {
    "passRate": {
      "threshold": 0.95,
      "description": "≥95% pass rate (4/4 valid runs)"
    },
    "truncation": {
      "threshold": 0,
      "description": "0 truncations (finishReason !== 'length')"
    },
    "modelDrift": {
      "threshold": 0,
      "description": "0 model drift (requested === resolved)"
    },
    "scoreImprovement": {
      "option1": {
        "description": "Beat Control by ≥3 points",
        "formula": "challenger_mean >= control_mean + 3.0"
      },
      "option2": {
        "description": "Match Control score with lower penalty",
        "formula": "challenger_mean >= control_mean AND (challenger_truthPenalty + challenger_qualityPenalty) <= (control_truthPenalty + control_qualityPenalty) - 0.02"
      }
    }
  },
  "controlBaseline": {
    "web": {
      "finalScore": {
        "mean": 97.8,
        "stddev": 1.2,
        "range": [95.4, 100.0]
      },
      "truthPenalty": {
        "mean": 0.028,
        "median": 0.030,
        "stddev": 0.013
      },
      "qualityPenalty": {
        "mean": 0.008,
        "median": 0.006,
        "stddev": 0.005
      }
    },
    "marketing": {
      "finalScore": {
        "mean": 97.1,
        "stddev": 1.5,
        "range": [94.1, 100.0]
      },
      "truthPenalty": {
        "mean": 0.021,
        "median": 0.015,
        "stddev": 0.018
      },
      "qualityPenalty": {
        "mean": 0.015,
        "median": 0.014,
        "stddev": 0.003
      }
    }
  },
  "expectedFailureModes": {
    "claimHallucination": "Marketing lane: May invent metrics/claims ('30% conversion boost', 'users hate X')",
    "implementationHallucination": "Web lane: May suggest unbuildable/vague UI changes ('make CTA more prominent' without placement)",
    "overconfidentCriticism": "May flag valid designs as flawed due to overly strict interpretation"
  },
  "outputs": {
    "resultsFile": "runs/pilot_1/PILOT_1_RESULTS.json",
    "scorecardFile": "runs/pilot_1/PILOT_1_SCORECARD.md",
    "comparisonFile": "runs/pilot_1/PILOT_1_VS_CONTROL.md"
  },
  "notes": [
    "Testing Sonnet as CRITIC first - if it can't be a reliable critic, no point testing as designer",
    "Web + Marketing combo catches both implementation-hallucination and claim-hallucination fastest",
    "Control baseline from 24-run soak test (2026-01-15)",
    "Pilot must pass 4/4 valid, 0 truncation, 0 drift before expanding to 4-lane tournament"
  ]
}
