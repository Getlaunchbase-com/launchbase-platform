{
  "generatedAt": "2026-01-15T14:45:00.000Z",
  "version": "1.0.0",
  "stack": "Control Champion (4o + Opus)",
  "policyName": "swarm_gate_a_control",
  "totalRuns": 14,
  "description": "Ground truth baseline for Control stack across all 4 lanes. Establishes reliability, honesty, and score variance bands for Model Weather tracking.",
  "lanes": {
    "web": {
      "runCount": 2,
      "passRate": 100,
      "truthPenalty": {
        "median": 0.017,
        "mean": 0.008,
        "stdDev": 0.012
      },
      "finalScore": {
        "mean": 99.2,
        "stdDev": 0.8,
        "lowerBound": 97.6,
        "upperBound": 100.8
      },
      "anchorCount": {
        "systems": { "mean": 5.0, "stdDev": 1.0 },
        "brand": { "mean": 6.0, "stdDev": 1.0 }
      },
      "cost": {
        "mean": 0.123,
        "stdDev": 0.005
      }
    },
    "app": {
      "runCount": 2,
      "passRate": 100,
      "truthPenalty": {
        "median": 0.0,
        "mean": 0.0,
        "stdDev": 0.0
      },
      "finalScore": {
        "mean": 100.0,
        "stdDev": 0.0,
        "lowerBound": 100.0,
        "upperBound": 100.0
      },
      "anchorCount": {
        "systems": { "mean": 7.0, "stdDev": 0.5 },
        "brand": { "mean": 7.5, "stdDev": 0.5 }
      },
      "cost": {
        "mean": 0.120,
        "stdDev": 0.003
      }
    },
    "marketing": {
      "runCount": 2,
      "passRate": 100,
      "truthPenalty": {
        "median": 0.033,
        "mean": 0.017,
        "stdDev": 0.024
      },
      "finalScore": {
        "mean": 98.3,
        "stdDev": 1.7,
        "lowerBound": 95.0,
        "upperBound": 101.7
      },
      "anchorCount": {
        "systems": { "mean": 3.5, "stdDev": 1.5 },
        "brand": { "mean": 4.5, "stdDev": 1.5 }
      },
      "cost": {
        "mean": 0.125,
        "stdDev": 0.005
      }
    },
    "artwork": {
      "runCount": 6,
      "passRate": 100,
      "truthPenalty": {
        "median": 0.100,
        "mean": 0.100,
        "stdDev": 0.0
      },
      "finalScore": {
        "mean": 90.0,
        "stdDev": 0.0,
        "lowerBound": 90.0,
        "upperBound": 90.0
      },
      "anchorCount": {
        "systems": { "mean": 0.67, "stdDev": 0.82 },
        "brand": { "mean": 5.0, "stdDev": 1.41 }
      },
      "cost": {
        "mean": 0.101,
        "stdDev": 0.002
      }
    }
  },
  "weatherThresholds": {
    "passRate": {
      "red": "<95%",
      "yellow": "95-98%",
      "green": "≥98%"
    },
    "truncations": {
      "red": ">0",
      "green": "=0"
    },
    "modelDrift": {
      "red": ">0",
      "green": "=0"
    },
    "truthPenaltyMedian": {
      "red": "≥0.20",
      "yellow": "0.10-0.19",
      "green": "<0.10"
    }
  },
  "challengerAcceptanceRules": {
    "reliability": "passRate ≥ 95% (≥5/6 or ≥19/20)",
    "noTruncation": "finishReason never 'length'",
    "scoreImprovement": "finalScore_mean ≥ control_mean + 3.0 OR (finalScore_mean ≥ control_mean AND truthPenalty_mean ≤ control_truth - 0.02)"
  }
}
