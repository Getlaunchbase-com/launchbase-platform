{
  "schemaId": "launchbase.baseline_truth",
  "schemaVersion": "1.2.0",
  "generatedAt": "2026-01-15T15:10:00Z",
  "compat": {
    "minRunnerVersion": ">=0.9.0"
  },
  "build": {
    "gitCommit": "45c8f41b5568b754aeef7b32d3a10df8e432ba68",
    "branch": "main",
    "dirty": false
  },
  "inputs": {
    "promptPackHash": "sha256:baseline_v1_prompts",
    "validatorHash": "sha256:contentValidator_v1_with_lane_specific_anchors",
    "truthPenaltyConfigHash": "sha256:truthPenalty_v1.0_weights"
  },
  "stack": "Control Champion (4o + Opus)",
  "policyName": "swarm_gate_a_control",
  "description": "Immutable ground-truth baseline for Control stack across four design lanes. Establishes reliability, honesty, and score variance bands for Model Weather tracking and challenger acceptance. Version 1.2 adds schema metadata, lane integrity counters, truth vs quality penalty split, role-level stats, registry snapshot, baseline confidence, and normalized score bounds.",
  "totalRuns": 14,
  "lanes": {
    "web": {
      "runCount": 2,
      "sampleSizeGrade": "low",
      "recommendedMinRunsForChallengerComparison": 6,
      "passRate": 100,
      "truthPenalty": {
        "median": 0.017,
        "mean": 0.008,
        "stdDev": 0.012
      },
      "qualityPenalty": {
        "median": 0.000,
        "mean": 0.000,
        "stdDev": 0.000
      },
      "finalScore": {
        "mean": 99.2,
        "stdDev": 0.8,
        "lowerBound": 97.6,
        "upperBound": 100.0
      },
      "anchorCount": {
        "systems": { "mean": 5.0, "stdDev": 1.0 },
        "brand": { "mean": 6.0, "stdDev": 1.0 }
      },
      "cost": {
        "mean": 0.123,
        "stdDev": 0.005
      },
      "duration": {
        "mean": 65.0,
        "stdDev": 5.0
      },
      "modelMeta": {
        "systems": "openai/gpt-4o-2024-08-06",
        "brand": "openai/gpt-4o-2024-08-06",
        "critic": "anthropic/claude-opus-4-1-20250805"
      },
      "integrity": {
        "truncationCount": 0,
        "modelDriftCount": 0,
        "invalidRunCount": 0,
        "contentPenaltyRate": 0.0
      },
      "roleStats": {
        "systems": {
          "jsonSizeBytesMean": 1800,
          "jsonSizeBytesStdDev": 150,
          "outputTokensMean": 580,
          "outputTokensStdDev": 50,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        },
        "brand": {
          "jsonSizeBytesMean": 1500,
          "jsonSizeBytesStdDev": 100,
          "outputTokensMean": 580,
          "outputTokensStdDev": 50,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        },
        "critic": {
          "jsonSizeBytesMean": 4700,
          "jsonSizeBytesStdDev": 400,
          "outputTokensMean": 1595,
          "outputTokensStdDev": 200,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        }
      }
    },
    "app": {
      "runCount": 2,
      "sampleSizeGrade": "low",
      "recommendedMinRunsForChallengerComparison": 6,
      "passRate": 100,
      "truthPenalty": {
        "median": 0.0,
        "mean": 0.0,
        "stdDev": 0.0
      },
      "qualityPenalty": {
        "median": 0.0,
        "mean": 0.0,
        "stdDev": 0.0
      },
      "finalScore": {
        "mean": 100.0,
        "stdDev": 0.0,
        "lowerBound": 100.0,
        "upperBound": 100.0
      },
      "anchorCount": {
        "systems": { "mean": 7.0, "stdDev": 0.5 },
        "brand": { "mean": 7.5, "stdDev": 0.5 }
      },
      "cost": {
        "mean": 0.120,
        "stdDev": 0.003
      },
      "duration": {
        "mean": 63.0,
        "stdDev": 4.0
      },
      "modelMeta": {
        "systems": "openai/gpt-4o-2024-08-06",
        "brand": "openai/gpt-4o-2024-08-06",
        "critic": "anthropic/claude-opus-4-1-20250805"
      },
      "integrity": {
        "truncationCount": 0,
        "modelDriftCount": 0,
        "invalidRunCount": 0,
        "contentPenaltyRate": 0.0
      },
      "roleStats": {
        "systems": {
          "jsonSizeBytesMean": 1850,
          "jsonSizeBytesStdDev": 120,
          "outputTokensMean": 590,
          "outputTokensStdDev": 45,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        },
        "brand": {
          "jsonSizeBytesMean": 1550,
          "jsonSizeBytesStdDev": 90,
          "outputTokensMean": 590,
          "outputTokensStdDev": 45,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        },
        "critic": {
          "jsonSizeBytesMean": 4800,
          "jsonSizeBytesStdDev": 350,
          "outputTokensMean": 1620,
          "outputTokensStdDev": 180,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        }
      }
    },
    "marketing": {
      "runCount": 2,
      "sampleSizeGrade": "low",
      "recommendedMinRunsForChallengerComparison": 6,
      "passRate": 100,
      "truthPenalty": {
        "median": 0.033,
        "mean": 0.017,
        "stdDev": 0.024
      },
      "qualityPenalty": {
        "median": 0.000,
        "mean": 0.000,
        "stdDev": 0.000
      },
      "finalScore": {
        "mean": 98.3,
        "stdDev": 1.7,
        "lowerBound": 95.0,
        "upperBound": 100.0
      },
      "anchorCount": {
        "systems": { "mean": 3.5, "stdDev": 1.5 },
        "brand": { "mean": 4.5, "stdDev": 1.5 }
      },
      "cost": {
        "mean": 0.125,
        "stdDev": 0.005
      },
      "duration": {
        "mean": 67.0,
        "stdDev": 6.0
      },
      "modelMeta": {
        "systems": "openai/gpt-4o-2024-08-06",
        "brand": "openai/gpt-4o-2024-08-06",
        "critic": "anthropic/claude-opus-4-1-20250805"
      },
      "integrity": {
        "truncationCount": 0,
        "modelDriftCount": 0,
        "invalidRunCount": 0,
        "contentPenaltyRate": 0.0
      },
      "roleStats": {
        "systems": {
          "jsonSizeBytesMean": 1750,
          "jsonSizeBytesStdDev": 180,
          "outputTokensMean": 570,
          "outputTokensStdDev": 60,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        },
        "brand": {
          "jsonSizeBytesMean": 1450,
          "jsonSizeBytesStdDev": 120,
          "outputTokensMean": 570,
          "outputTokensStdDev": 60,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        },
        "critic": {
          "jsonSizeBytesMean": 4650,
          "jsonSizeBytesStdDev": 420,
          "outputTokensMean": 1580,
          "outputTokensStdDev": 220,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        }
      }
    },
    "artwork": {
      "runCount": 6,
      "sampleSizeGrade": "medium",
      "recommendedMinRunsForChallengerComparison": 6,
      "passRate": 100,
      "truthPenalty": {
        "median": 0.000,
        "mean": 0.000,
        "stdDev": 0.0
      },
      "qualityPenalty": {
        "median": 0.100,
        "mean": 0.100,
        "stdDev": 0.0
      },
      "finalScore": {
        "mean": 90.0,
        "stdDev": 0.0,
        "lowerBound": 90.0,
        "upperBound": 90.0
      },
      "anchorCount": {
        "systems": { "mean": 0.67, "stdDev": 0.82 },
        "brand": { "mean": 5.0, "stdDev": 1.41 }
      },
      "cost": {
        "mean": 0.101,
        "stdDev": 0.002
      },
      "duration": {
        "mean": 61.0,
        "stdDev": 3.8
      },
      "modelMeta": {
        "systems": "openai/gpt-4o-2024-08-06",
        "brand": "openai/gpt-4o-2024-08-06",
        "critic": "anthropic/claude-opus-4-1-20250805"
      },
      "integrity": {
        "truncationCount": 0,
        "modelDriftCount": 0,
        "invalidRunCount": 0,
        "contentPenaltyRate": 100.0
      },
      "roleStats": {
        "systems": {
          "jsonSizeBytesMean": 1650,
          "jsonSizeBytesStdDev": 200,
          "outputTokensMean": 550,
          "outputTokensStdDev": 70,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        },
        "brand": {
          "jsonSizeBytesMean": 1500,
          "jsonSizeBytesStdDev": 150,
          "outputTokensMean": 560,
          "outputTokensStdDev": 65,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        },
        "critic": {
          "jsonSizeBytesMean": 4600,
          "jsonSizeBytesStdDev": 380,
          "outputTokensMean": 1560,
          "outputTokensStdDev": 190,
          "stopReasonDistribution": { "end_turn": 100.0, "length": 0.0 }
        }
      }
    }
  },
  "laneContracts": {
    "web": {
      "designAnchorsMin": 3,
      "criticIssuesMin": 10,
      "criticFixesMin": 10,
      "description": "Web lane requires concrete UI specs (≥3 anchors per designer)"
    },
    "app": {
      "designAnchorsMin": 3,
      "criticIssuesMin": 10,
      "criticFixesMin": 10,
      "description": "App lane requires concrete component specs (≥3 anchors per designer)"
    },
    "marketing": {
      "designAnchorsMin": 0,
      "criticIssuesMin": 10,
      "criticFixesMin": 10,
      "description": "Marketing lane allows strategic changes with minimal anchors (penalty-based, not hard fail)"
    },
    "artwork": {
      "designAnchorsMin": 0,
      "criticIssuesMin": 10,
      "criticFixesMin": 10,
      "description": "Artwork lane allows visual/strategic changes with minimal anchors (penalty-based, not hard fail)"
    }
  },
  "truthPenaltyBreakdownBaseline": {
    "web": {
      "unverifiable": 0.008,
      "invented": 0.000,
      "vague": 0.000,
      "strain": 0.000,
      "description": "Web lane has minimal truth penalties (mostly from unverifiable claims)"
    },
    "app": {
      "unverifiable": 0.000,
      "invented": 0.000,
      "vague": 0.000,
      "strain": 0.000,
      "description": "App lane has zero truth penalties (perfect honesty baseline)"
    },
    "marketing": {
      "unverifiable": 0.010,
      "invented": 0.000,
      "vague": 0.007,
      "strain": 0.000,
      "description": "Marketing lane has minor vagueness penalties (expected for strategic messaging)"
    },
    "artwork": {
      "unverifiable": 0.000,
      "invented": 0.000,
      "vague": 0.000,
      "strain": 0.000,
      "description": "Artwork lane has zero truth penalties (all penalty is quality-based from low anchors)"
    }
  },
  "laneScoringWeights": {
    "web": {
      "base": 1.0,
      "truthPenaltyMultiplier": 1.0,
      "qualityPenaltyMultiplier": 1.0,
      "description": "Standard scoring (no adjustments)"
    },
    "app": {
      "base": 1.0,
      "truthPenaltyMultiplier": 1.0,
      "qualityPenaltyMultiplier": 1.0,
      "description": "Standard scoring (no adjustments)"
    },
    "marketing": {
      "base": 1.0,
      "truthPenaltyMultiplier": 1.2,
      "qualityPenaltyMultiplier": 0.9,
      "description": "Higher truth penalty weight (strategic claims must be verifiable), lower quality penalty (strategic changes naturally less anchored)"
    },
    "artwork": {
      "base": 1.0,
      "truthPenaltyMultiplier": 1.0,
      "qualityPenaltyMultiplier": 0.8,
      "description": "Lower quality penalty weight (visual/strategic changes naturally less anchored)"
    }
  },
  "metrics": {
    "jsonSizeBytes": {
      "systems": { "mean": 1750, "stdDev": 170 },
      "brand": { "mean": 1500, "stdDev": 120 },
      "critic": { "mean": 4688, "stdDev": 388 }
    },
    "tokens": {
      "inputMean": 850,
      "outputMean": 580,
      "inputStdDev": 50,
      "outputStdDev": 100
    },
    "finishReasonDistribution": {
      "end_turn": 100.0,
      "stop": 0.0,
      "length": 0.0,
      "provider_failed": 0.0
    },
    "retryDistribution": {
      "noRetry": 100.0,
      "oneRetry": 0.0,
      "twoRetries": 0.0,
      "allRetriesFailed": 0.0
    }
  },
  "weatherThresholds": {
    "passRate": {
      "red": "<95%",
      "yellow": "95-98%",
      "green": "≥98%"
    },
    "truthPenaltyMedian": {
      "red": "≥0.20",
      "yellow": "0.10-0.19",
      "green": "<0.10"
    },
    "qualityPenaltyMedian": {
      "red": "≥0.30",
      "yellow": "0.15-0.29",
      "green": "<0.15"
    },
    "truncations": {
      "red": ">0",
      "green": "=0"
    },
    "modelDrift": {
      "red": ">0",
      "green": "=0"
    },
    "retryRate": {
      "red": ">10%",
      "yellow": "5-10%",
      "green": "<5%"
    }
  },
  "challengerAcceptanceRules": {
    "reliability": "passRate ≥ 95% (≥5/6 or ≥19/20)",
    "noTruncation": "finishReason never 'length'",
    "noDrift": "requested model == resolved model (MODEL_LOCK) for all steps",
    "scoreImprovement": "finalScore_mean ≥ control_mean + 3.0 OR (finalScore_mean ≥ control_mean AND (truthPenalty_mean + qualityPenalty_mean) ≤ (control_truth + control_quality) - 0.02)",
    "noVagueWins": "Cannot win solely by higher qualityPenalty or lower anchorCount without real score gain",
    "laneEligibility": "Must be approved for specific lane (text LLMs for web/app/marketing, image models for artwork only)"
  },
  "challengerClasses": {
    "text_llm": {
      "models": [
        "anthropic/claude-3.5-sonnet",
        "xai/grok-4-1-fast-reasoning",
        "openai/gpt-4o-2024-08-06",
        "openai/gpt-5-2025-08-07",
        "openai/o3-pro"
      ],
      "artifactKind": "json",
      "description": "General-purpose text LLMs for code, copy, and structured JSON generation"
    },
    "low_latency_llm": {
      "models": [
        "groq/llama-3.1-70b"
      ],
      "artifactKind": "json",
      "description": "Specialized hardware-accelerated LLMs for low-latency structured output"
    },
    "image_gen": {
      "models": [
        "stability-ai/sd3",
        "black-forest-labs/flux-1.1-pro"
      ],
      "artifactKind": "image",
      "description": "Image generation models for visual assets, illustrations, and branded graphics (artwork lane only)"
    },
    "ui_builder": {
      "models": [
        "google/stitch"
      ],
      "artifactKind": "mixed",
      "description": "Text-to-UI generation systems (Gemini-backed, multimodal design automation)"
    }
  },
  "laneEligibility": {
    "web": [
      "anthropic/claude-3.5-sonnet",
      "xai/grok-4-1-fast-reasoning",
      "groq/llama-3.1-70b",
      "openai/gpt-5-2025-08-07",
      "openai/o3-pro",
      "google/stitch"
    ],
    "app": [
      "anthropic/claude-3.5-sonnet",
      "xai/grok-4-1-fast-reasoning",
      "groq/llama-3.1-70b",
      "openai/gpt-5-2025-08-07",
      "openai/o3-pro",
      "google/stitch"
    ],
    "marketing": [
      "anthropic/claude-3.5-sonnet",
      "xai/grok-4-1-fast-reasoning",
      "groq/llama-3.1-70b",
      "openai/gpt-5-2025-08-07",
      "openai/o3-pro"
    ],
    "artwork": [
      "stability-ai/sd3",
      "black-forest-labs/flux-1.1-pro",
      "anthropic/claude-3.5-sonnet",
      "xai/grok-4-1-fast-reasoning"
    ]
  },
  "registrySnapshot": {
    "generatedAt": "2026-01-15T15:10:00Z",
    "source": "aiml_model_registry",
    "verifiedAvailable": [
      "openai/gpt-4o-2024-08-06",
      "anthropic/claude-opus-4-1-20250805",
      "anthropic/claude-3.5-sonnet"
    ],
    "knownUnavailable": [
      "openai/gpt-5-2025-08-07",
      "openai/o3-pro"
    ],
    "knownTruncationRisk": [
      "google/gemini-2.5-pro"
    ],
    "pendingVerification": [
      "xai/grok-4-1-fast-reasoning",
      "groq/llama-3.1-70b",
      "stability-ai/sd3",
      "black-forest-labs/flux-1.1-pro",
      "google/stitch"
    ]
  },
  "approvedChallengers": [
    {
      "id": "anthropic/claude-3.5-sonnet",
      "name": "Claude 3.5 Sonnet",
      "class": "text_llm",
      "artifactKind": "json",
      "use": "Layout & Frontend Code",
      "roleEligibility": ["designer_systems_fast", "designer_brand_fast", "design_critic_ruthless"],
      "maxTokensRecommendation": { "designer": 2500, "critic": 4000 },
      "eligibleLanes": ["web", "app", "marketing", "artwork"],
      "status": "pending_pilot",
      "expectedFailureModes": []
    },
    {
      "id": "google/stitch",
      "name": "Google Stitch (Gemini 2.5 Pro)",
      "class": "ui_builder",
      "artifactKind": "mixed",
      "use": "Text-to-UI Generation",
      "roleEligibility": ["designer_systems_fast", "designer_brand_fast"],
      "maxTokensRecommendation": { "designer": 3500, "critic": 0 },
      "eligibleLanes": ["web", "app"],
      "status": "pending_pilot",
      "expectedFailureModes": ["truncation"]
    },
    {
      "id": "stability-ai/sd3",
      "name": "Stable Diffusion 3",
      "class": "image_gen",
      "artifactKind": "image",
      "use": "Visual Assets & UI Mockups",
      "roleEligibility": ["artwork_asset_generator"],
      "maxTokensRecommendation": {},
      "eligibleLanes": ["artwork"],
      "status": "pending_pilot",
      "expectedFailureModes": []
    },
    {
      "id": "black-forest-labs/flux-1.1-pro",
      "name": "Flux 1.1 Pro",
      "class": "image_gen",
      "artifactKind": "image",
      "use": "Branded Graphics & Illustrations",
      "roleEligibility": ["artwork_asset_generator"],
      "maxTokensRecommendation": {},
      "eligibleLanes": ["artwork"],
      "status": "pending_pilot",
      "expectedFailureModes": []
    },
    {
      "id": "xai/grok-4-1-fast-reasoning",
      "name": "xAI Grok 4.1 Fast (Reasoning)",
      "class": "text_llm",
      "artifactKind": "json",
      "use": "Multimodal Brainstorming & Layout Sketches",
      "roleEligibility": ["designer_systems_fast", "designer_brand_fast", "design_critic_ruthless"],
      "maxTokensRecommendation": { "designer": 2500, "critic": 4000 },
      "eligibleLanes": ["web", "app", "marketing", "artwork"],
      "status": "pending_pilot",
      "expectedFailureModes": []
    },
    {
      "id": "groq/llama-3.1-70b",
      "name": "Groq LPU (LLAMA 3.1 70B)",
      "class": "low_latency_llm",
      "artifactKind": "json",
      "use": "Low-Latency Code Synthesis",
      "roleEligibility": ["designer_systems_fast", "designer_brand_fast"],
      "maxTokensRecommendation": { "designer": 2000, "critic": 0 },
      "eligibleLanes": ["web", "app", "marketing"],
      "status": "pending_pilot",
      "expectedFailureModes": ["schema_drift"]
    },
    {
      "id": "openai/gpt-5-2025-08-07",
      "name": "GPT-5",
      "class": "text_llm",
      "artifactKind": "json",
      "use": "Strategic Copy & UX Writing",
      "roleEligibility": ["designer_systems_fast", "designer_brand_fast", "design_critic_ruthless"],
      "maxTokensRecommendation": { "designer": 2500, "critic": 4000 },
      "eligibleLanes": ["web", "app", "marketing"],
      "status": "pending_availability",
      "expectedFailureModes": []
    },
    {
      "id": "openai/o3-pro",
      "name": "O3-Pro",
      "class": "text_llm",
      "artifactKind": "json",
      "use": "Complex Reasoning & Architecture",
      "roleEligibility": ["designer_systems_fast", "designer_brand_fast", "design_critic_ruthless"],
      "maxTokensRecommendation": { "designer": 3000, "critic": 4500 },
      "eligibleLanes": ["web", "app", "marketing"],
      "status": "pending_availability",
      "expectedFailureModes": []
    },
    {
      "id": "google/gemini-2.5-pro",
      "name": "Gemini 2.5 Pro",
      "class": "text_llm",
      "artifactKind": "json",
      "use": "Multimodal Design & Code",
      "roleEligibility": ["designer_systems_fast", "designer_brand_fast", "design_critic_ruthless"],
      "maxTokensRecommendation": { "designer": 4500, "critic": 6000 },
      "eligibleLanes": ["web", "app", "marketing"],
      "status": "failed_pilot",
      "reason": "100% truncation rate at maxTokens=3000, needs tuning (char caps or maxTokens=4500-6000)",
      "expectedFailureModes": ["truncation"]
    }
  ],
  "notes": {
    "artworkLaneBehavior": "Artwork lane naturally has lower anchor counts on systems side (0.67 avg) due to strategic/visual nature of changes. Brand designer maintains specificity (5.0 avg anchors). All penalty is quality-based (0.100), not truth-based (0.000). This is expected and correct.",
    "zeroVarianceLanes": "App and Artwork lanes show zero score variance (σ=0.0), indicating highly consistent Control stack performance. This is the gold standard for challenger comparison.",
    "truthVsQualitySplit": "v1.2 separates truthPenalty (hallucination/invented/unverifiable) from qualityPenalty (vagueness/low-anchor). Artwork lane has 0.0 truth penalty but 0.1 quality penalty. This allows 'honest but vague' vs 'lying' distinction.",
    "laneContractRationale": "Marketing and Artwork lanes allow 0 minimum anchors (penalty-based validation) because strategic/visual changes are naturally less concrete than UI/component specs. Web and App lanes require ≥3 anchors to ensure implementability.",
    "challengerClassification": "Image generation models (SD3, Flux) are ONLY eligible for artwork lane and output artifactKind='image'. Text LLMs compete in web/app/marketing with artifactKind='json'. UI builders (Stitch) compete in web/app with artifactKind='mixed'. This prevents 'apples to oranges' comparisons.",
    "sampleSizeWarnings": "Web, App, and Marketing lanes have only 2 runs each (sampleSizeGrade='low'). Recommended minimum is 6 runs for reliable challenger comparison. Artwork lane has 6 runs (sampleSizeGrade='medium').",
    "scoreBoundsNormalization": "All finalScore upperBounds clamped to 100.0 and lowerBounds clamped to 0.0 (was 100.8 for web in v1.1). This prevents dashboard noise from statistical artifacts.",
    "nextSteps": [
      "Run 24-run Control soak test (6 reps × 4 lanes) to upgrade all lanes to sampleSizeGrade='medium' and tighten variance bands",
      "Build Model Weather Dashboard with pass rate, truthPenalty trends, qualityPenalty trends, token drift, penalty breakdown visualization, role-level stats",
      "Run preflight + pilot for approved challengers (Claude 3.5, Stitch, Grok, Groq, SD3, Flux)",
      "Launch full Challenger Tournament once ≥2 challengers pass pilot validation (≥95% pass, 0 truncations, beat Control by ≥3 pts)"
    ]
  }
}
